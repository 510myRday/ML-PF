{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d203ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "531427fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义函数 -----------------------------------------------------------------------------------------------------\n",
    "def name_to_str(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def find_index(index, pred_type):\n",
    "    equal = np.empty(0)\n",
    "    for i in np.arange(0, pred_type.size):\n",
    "        count = index.count(pred_type[i])\n",
    "        if count == 0:\n",
    "            equal = np.append(equal, \"False\")\n",
    "        else:\n",
    "            equal = np.append(equal, \"True\")\n",
    "    return pd.DataFrame({\"equal\":equal})\n",
    "\n",
    "def result(test_x, test_y):\n",
    "    # 预测\n",
    "    pred = model.predict(test_x)\n",
    "    truth_type = test_y.argmax(axis = 1)\n",
    "    pred_type = pred.argmax(axis = 1)\n",
    "    \n",
    "    # test准确性\n",
    "    single_accuracy = round(model.evaluate(test_x, test_y)[1], 3)\n",
    "    print(\"\\n★--- Single_accuracy:\", single_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    # 获取对应索引\n",
    "    name = name_to_str(pred_x,globals())[0]\n",
    "    if name == \"x_test_normal\": class_index = normal_index; total_index = normal_index\n",
    "    if name == \"x_test_speeding\": class_index = speeding_index; total_index = aberrant_index\n",
    "    if name == \"x_test_cheating\": class_index = cheating_index; total_index = aberrant_index\n",
    "    if name == \"x_test_r_guessing\": class_index = r_guessing_index; total_index = aberrant_index\n",
    "    # print(class_index, total_index)\n",
    "    \n",
    "    # class准确性\n",
    "    class_df = find_index(class_index, pred_type)\n",
    "    class_accuracy = round(class_df.value_counts()[\"True\"] / class_df.size, 3)\n",
    "    \n",
    "    print(\"\\n★--- Class_accuracy:\", class_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    # total准确性\n",
    "    total_df = find_index(total_index, pred_type)\n",
    "    total_accuracy = round(total_df.value_counts()[\"True\"] / total_df.size, 3)\n",
    "    print(\"\\n★--- Total_accuracy:\", total_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    return single_accuracy, class_accuracy, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "413f5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/12 22:26:02\n",
      "--------------------- running 1 ---------------------\n",
      "x_train.shape: (10000, 10)\n",
      "y_train.shape: (10000, 32)\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 3.3581 - accuracy: 0.0751 - val_loss: 3.2340 - val_accuracy: 0.0984\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 3.1278 - accuracy: 0.0962 - val_loss: 3.0177 - val_accuracy: 0.1033\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.9178 - accuracy: 0.1358 - val_loss: 2.8139 - val_accuracy: 0.1749\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.7182 - accuracy: 0.2183 - val_loss: 2.6188 - val_accuracy: 0.2652\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.5329 - accuracy: 0.2748 - val_loss: 2.4453 - val_accuracy: 0.3128\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3683 - accuracy: 0.3341 - val_loss: 2.2888 - val_accuracy: 0.3971\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2188 - accuracy: 0.4009 - val_loss: 2.1462 - val_accuracy: 0.4073\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0824 - accuracy: 0.4230 - val_loss: 2.0158 - val_accuracy: 0.4629\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.9587 - accuracy: 0.5015 - val_loss: 1.8992 - val_accuracy: 0.5610\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8486 - accuracy: 0.5889 - val_loss: 1.7962 - val_accuracy: 0.6057\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7520 - accuracy: 0.6370 - val_loss: 1.7063 - val_accuracy: 0.6482\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6682 - accuracy: 0.6549 - val_loss: 1.6282 - val_accuracy: 0.6532\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5952 - accuracy: 0.6637 - val_loss: 1.5598 - val_accuracy: 0.6613\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5317 - accuracy: 0.6677 - val_loss: 1.5005 - val_accuracy: 0.6626\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4760 - accuracy: 0.6712 - val_loss: 1.4478 - val_accuracy: 0.6683\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4266 - accuracy: 0.6741 - val_loss: 1.4011 - val_accuracy: 0.6743\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3826 - accuracy: 0.6778 - val_loss: 1.3595 - val_accuracy: 0.6739\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3429 - accuracy: 0.6778 - val_loss: 1.3220 - val_accuracy: 0.6799\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3069 - accuracy: 0.6852 - val_loss: 1.2876 - val_accuracy: 0.6913\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2742 - accuracy: 0.6901 - val_loss: 1.2566 - val_accuracy: 0.6937\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2442 - accuracy: 0.6929 - val_loss: 1.2279 - val_accuracy: 0.6947\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2167 - accuracy: 0.6937 - val_loss: 1.2015 - val_accuracy: 0.6963\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1913 - accuracy: 0.6958 - val_loss: 1.1773 - val_accuracy: 0.6972\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1680 - accuracy: 0.6980 - val_loss: 1.1551 - val_accuracy: 0.6996\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1465 - accuracy: 0.7006 - val_loss: 1.1346 - val_accuracy: 0.6997\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1268 - accuracy: 0.7059 - val_loss: 1.1157 - val_accuracy: 0.7012\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1087 - accuracy: 0.7069 - val_loss: 1.0986 - val_accuracy: 0.7048\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0920 - accuracy: 0.7081 - val_loss: 1.0826 - val_accuracy: 0.7067\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0765 - accuracy: 0.7091 - val_loss: 1.0682 - val_accuracy: 0.7078\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0622 - accuracy: 0.7099 - val_loss: 1.0545 - val_accuracy: 0.7080\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0490 - accuracy: 0.7094 - val_loss: 1.0419 - val_accuracy: 0.7082\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0369 - accuracy: 0.7098 - val_loss: 1.0306 - val_accuracy: 0.7084\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0256 - accuracy: 0.7100 - val_loss: 1.0203 - val_accuracy: 0.7118\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0151 - accuracy: 0.7103 - val_loss: 1.0102 - val_accuracy: 0.7120\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0055 - accuracy: 0.7130 - val_loss: 1.0016 - val_accuracy: 0.7118\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9966 - accuracy: 0.7141 - val_loss: 0.9930 - val_accuracy: 0.7119\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9885 - accuracy: 0.7142 - val_loss: 0.9852 - val_accuracy: 0.7122\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9807 - accuracy: 0.7145 - val_loss: 0.9782 - val_accuracy: 0.7122\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9736 - accuracy: 0.7142 - val_loss: 0.9714 - val_accuracy: 0.7114\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9669 - accuracy: 0.7144 - val_loss: 0.9652 - val_accuracy: 0.7114\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9607 - accuracy: 0.7141 - val_loss: 0.9593 - val_accuracy: 0.7117\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9549 - accuracy: 0.7149 - val_loss: 0.9541 - val_accuracy: 0.7126\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9495 - accuracy: 0.7143 - val_loss: 0.9493 - val_accuracy: 0.7114\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9443 - accuracy: 0.7162 - val_loss: 0.9446 - val_accuracy: 0.7120\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9395 - accuracy: 0.7164 - val_loss: 0.9403 - val_accuracy: 0.7112\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9350 - accuracy: 0.7160 - val_loss: 0.9358 - val_accuracy: 0.7121\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9308 - accuracy: 0.7171 - val_loss: 0.9318 - val_accuracy: 0.7127\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9266 - accuracy: 0.7169 - val_loss: 0.9282 - val_accuracy: 0.7125\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9229 - accuracy: 0.7177 - val_loss: 0.9246 - val_accuracy: 0.7129\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9192 - accuracy: 0.7176 - val_loss: 0.9213 - val_accuracy: 0.7135\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9157 - accuracy: 0.7182 - val_loss: 0.9183 - val_accuracy: 0.7133\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9125 - accuracy: 0.7180 - val_loss: 0.9152 - val_accuracy: 0.7136\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9093 - accuracy: 0.7204 - val_loss: 0.9123 - val_accuracy: 0.7159\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9063 - accuracy: 0.7211 - val_loss: 0.9096 - val_accuracy: 0.7157\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9035 - accuracy: 0.7223 - val_loss: 0.9070 - val_accuracy: 0.7157\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9008 - accuracy: 0.7227 - val_loss: 0.9045 - val_accuracy: 0.7158\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8982 - accuracy: 0.7217 - val_loss: 0.9021 - val_accuracy: 0.7159\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8956 - accuracy: 0.7228 - val_loss: 0.9000 - val_accuracy: 0.7165\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8933 - accuracy: 0.7228 - val_loss: 0.8978 - val_accuracy: 0.7165\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8909 - accuracy: 0.7238 - val_loss: 0.8958 - val_accuracy: 0.7172\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8887 - accuracy: 0.7238 - val_loss: 0.8939 - val_accuracy: 0.7167\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8866 - accuracy: 0.7235 - val_loss: 0.8919 - val_accuracy: 0.7169\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8846 - accuracy: 0.7235 - val_loss: 0.8897 - val_accuracy: 0.7178\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8827 - accuracy: 0.7234 - val_loss: 0.8881 - val_accuracy: 0.7184\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8808 - accuracy: 0.7236 - val_loss: 0.8864 - val_accuracy: 0.7181\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8791 - accuracy: 0.7235 - val_loss: 0.8844 - val_accuracy: 0.7179\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8772 - accuracy: 0.7245 - val_loss: 0.8830 - val_accuracy: 0.7186\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8756 - accuracy: 0.7244 - val_loss: 0.8817 - val_accuracy: 0.7189\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8740 - accuracy: 0.7245 - val_loss: 0.8799 - val_accuracy: 0.7188\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8723 - accuracy: 0.7262 - val_loss: 0.8784 - val_accuracy: 0.7188\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8707 - accuracy: 0.7261 - val_loss: 0.8770 - val_accuracy: 0.7187\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8692 - accuracy: 0.7260 - val_loss: 0.8755 - val_accuracy: 0.7203\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8677 - accuracy: 0.7260 - val_loss: 0.8743 - val_accuracy: 0.7208\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8664 - accuracy: 0.7269 - val_loss: 0.8733 - val_accuracy: 0.7213\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8649 - accuracy: 0.7273 - val_loss: 0.8715 - val_accuracy: 0.7204\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8637 - accuracy: 0.7271 - val_loss: 0.8706 - val_accuracy: 0.7211\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8624 - accuracy: 0.7275 - val_loss: 0.8697 - val_accuracy: 0.7214\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8611 - accuracy: 0.7278 - val_loss: 0.8683 - val_accuracy: 0.7211\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8600 - accuracy: 0.7277 - val_loss: 0.8671 - val_accuracy: 0.7214\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8588 - accuracy: 0.7281 - val_loss: 0.8660 - val_accuracy: 0.7212\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8577 - accuracy: 0.7281 - val_loss: 0.8650 - val_accuracy: 0.7210\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8564 - accuracy: 0.7288 - val_loss: 0.8640 - val_accuracy: 0.7209\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8553 - accuracy: 0.7290 - val_loss: 0.8632 - val_accuracy: 0.7213\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8544 - accuracy: 0.7285 - val_loss: 0.8621 - val_accuracy: 0.7214\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8533 - accuracy: 0.7294 - val_loss: 0.8612 - val_accuracy: 0.7215\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8524 - accuracy: 0.7290 - val_loss: 0.8601 - val_accuracy: 0.7217\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8513 - accuracy: 0.7294 - val_loss: 0.8595 - val_accuracy: 0.7214\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8505 - accuracy: 0.7290 - val_loss: 0.8584 - val_accuracy: 0.7218\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8495 - accuracy: 0.7287 - val_loss: 0.8576 - val_accuracy: 0.7223\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8487 - accuracy: 0.7301 - val_loss: 0.8569 - val_accuracy: 0.7217\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8477 - accuracy: 0.7292 - val_loss: 0.8558 - val_accuracy: 0.7220\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8468 - accuracy: 0.7290 - val_loss: 0.8552 - val_accuracy: 0.7219\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8461 - accuracy: 0.7292 - val_loss: 0.8542 - val_accuracy: 0.7219\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8453 - accuracy: 0.7288 - val_loss: 0.8536 - val_accuracy: 0.7224\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8445 - accuracy: 0.7297 - val_loss: 0.8527 - val_accuracy: 0.7227\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8437 - accuracy: 0.7294 - val_loss: 0.8520 - val_accuracy: 0.7225\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8429 - accuracy: 0.7303 - val_loss: 0.8516 - val_accuracy: 0.7229\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8423 - accuracy: 0.7295 - val_loss: 0.8508 - val_accuracy: 0.7228\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8414 - accuracy: 0.7301 - val_loss: 0.8502 - val_accuracy: 0.7228\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8408 - accuracy: 0.7299 - val_loss: 0.8495 - val_accuracy: 0.7225\n",
      "['x_test_normal', 'pred_x']\n",
      "125/125 [==============================] - 0s 665us/step\n",
      "125/125 [==============================] - 0s 826us/step - loss: 0.6860 - accuracy: 0.8230\n",
      "\n",
      "★--- Single_accuracy: 0.823\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.904\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.904\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_speeding', 'pred_x']\n",
      "63/63 [==============================] - 0s 689us/step\n",
      "63/63 [==============================] - 0s 745us/step - loss: 0.8573 - accuracy: 0.5430\n",
      "\n",
      "★--- Single_accuracy: 0.543\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.55\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.599\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_cheating', 'pred_x']\n",
      "110/110 [==============================] - 0s 617us/step\n",
      "110/110 [==============================] - 0s 728us/step - loss: 0.6152 - accuracy: 0.7983\n",
      "\n",
      "★--- Single_accuracy: 0.798\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.917\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.949\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_r_guessing', 'pred_x']\n",
      "16/16 [==============================] - 0s 698us/step\n",
      "16/16 [==============================] - 0s 827us/step - loss: 3.9173 - accuracy: 0.0060\n",
      "\n",
      "★--- Single_accuracy: 0.006\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.122\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.33\n",
      "\n",
      "------------------------------------------------------------------\n",
      "2022/11/12 22:28:43\n"
     ]
    }
   ],
   "source": [
    "# 生成保存结果的数组 -----------------\n",
    "normal_single_accuracy = np.empty(0)\n",
    "speeding_single_accuracy = np.empty(0)\n",
    "cheating_single_accuracy = np.empty(0)\n",
    "r_guessing_single_accuracy = np.empty(0)\n",
    "\n",
    "normal_class_accuracy = np.empty(0)\n",
    "speeding_class_accuracy = np.empty(0)\n",
    "cheating_class_accuracy = np.empty(0)\n",
    "r_guessing_class_accuracy = np.empty(0)\n",
    "\n",
    "normal_total_accuracy = np.empty(0)\n",
    "speeding_total_accuracy = np.empty(0)\n",
    "cheating_total_accuracy = np.empty(0)\n",
    "r_guessing_total_accuracy = np.empty(0)\n",
    "\n",
    "# 重复50次 (1:51) -----------------------------\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()))\n",
    "for rs in np.arange(1, 2):\n",
    "    \n",
    "    ########## 数据参数 ##########\n",
    "    start_name = \"Q_3_10_high_0.2\"\n",
    "    seed = str(rs)\n",
    "    hasRT = \"F\"\n",
    "    ##############################\n",
    "    print(\"--------------------- running \" + seed + \" ---------------------\")\n",
    "    \n",
    "    # 读入数据 ---------------------\n",
    "    train_x_path = \"./DATA2/\" + seed + \"s_\" + start_name + \"_train_x_\" + hasRT + \".csv\"\n",
    "    train_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_train_y.csv\"\n",
    "\n",
    "    test_normal_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_normal_x_\" + hasRT + \".csv\"\n",
    "    test_normal_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_normal_y.csv\"\n",
    "    test_cheating_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_cheating_x_\" + hasRT + \".csv\"\n",
    "    test_cheating_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_cheating_y.csv\"\n",
    "    test_speeding_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_speeding_x_\" + hasRT + \".csv\"\n",
    "    test_speeding_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_speeding_y.csv\"\n",
    "    test_r_guessing_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_r_guessing_x_\" + hasRT + \".csv\"\n",
    "    test_r_guessing_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_r_guessing_y.csv\"\n",
    "\n",
    "    x_train = np.array(pd.read_csv(train_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_train = np.array(pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "\n",
    "    x_test_normal = np.array(pd.read_csv(test_normal_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_normal = np.array(pd.read_csv(test_normal_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_cheating = np.array(pd.read_csv(test_cheating_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_cheating = np.array(pd.read_csv(test_cheating_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_speeding = np.array(pd.read_csv(test_speeding_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_speeding = np.array(pd.read_csv(test_speeding_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_r_guessing = np.array(pd.read_csv(test_r_guessing_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_r_guessing = np.array(pd.read_csv(test_r_guessing_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "\n",
    "    # 获取异常类索引 ---------------\n",
    "    def get_same_element_index(ob_list, word):\n",
    "        return [i for (i, v) in enumerate(ob_list) if v == word]\n",
    "\n",
    "    normal_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('normal').tolist()\n",
    "    speeding_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('speeding').tolist()\n",
    "    cheating_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('cheating').tolist()\n",
    "    r_guessing_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('r_guessing').tolist()\n",
    "\n",
    "    normal_index = get_same_element_index(normal_list, True)\n",
    "    aberrant_index = get_same_element_index(normal_list, False)\n",
    "    speeding_index = get_same_element_index(speeding_list, True)\n",
    "    cheating_index = get_same_element_index(cheating_list, True)\n",
    "    r_guessing_index = get_same_element_index(r_guessing_list, True)\n",
    "    \n",
    "\n",
    "    # 训练集——测试集划分（5-5） ---\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,train_size=0.5,random_state=666)\n",
    "    print(\"x_train.shape:\", x_train.shape)\n",
    "    print(\"y_train.shape:\", y_train.shape)\n",
    "    \n",
    "    ########## 模型参数 ##########\n",
    "    layer_one = x_train.shape[1] - 1\n",
    "    batch_size = int(x_train.shape[0] / 1000)\n",
    "    learning_rate=0.0001\n",
    "    epochs = 100\n",
    "    ##############################\n",
    "    \n",
    "    # 构建模型 -----------------------\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = layer_one, input_dim = x_train.shape[1], activation = \"relu\"))\n",
    "    model.add(Dense(units = y_train.shape[1], activation = \"softmax\"))\n",
    "    \n",
    "    adam = Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    \n",
    "    # 训练模型 ------------------------\n",
    "    H = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), workers=20, use_multiprocessing=True)\n",
    "    \n",
    "    # normal结果 ----------------------\n",
    "    pred_x = x_test_normal\n",
    "    pred_y = y_test_normal\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    normal_single_accuracy = np.append(normal_single_accuracy, single_accuracy)\n",
    "    normal_class_accuracy = np.append(normal_class_accuracy, class_accuracy)\n",
    "    normal_total_accuracy = np.append(normal_total_accuracy, total_accuracy)\n",
    "    \n",
    "    # speeding结果 --------------------\n",
    "    pred_x = x_test_speeding\n",
    "    pred_y = y_test_speeding\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    speeding_single_accuracy = np.append(speeding_single_accuracy, single_accuracy)\n",
    "    speeding_class_accuracy = np.append(speeding_class_accuracy, class_accuracy)\n",
    "    speeding_total_accuracy = np.append(speeding_total_accuracy, total_accuracy)\n",
    "\n",
    "    # cheating结果 ---------------------\n",
    "    pred_x = x_test_cheating\n",
    "    pred_y = y_test_cheating\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    cheating_single_accuracy = np.append(cheating_single_accuracy, single_accuracy)\n",
    "    cheating_class_accuracy = np.append(cheating_class_accuracy, class_accuracy)\n",
    "    cheating_total_accuracy = np.append(cheating_total_accuracy, total_accuracy)\n",
    "\n",
    "    # r_guessing结果 -------------------\n",
    "    pred_x = x_test_r_guessing\n",
    "    pred_y = y_test_r_guessing\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    r_guessing_single_accuracy = np.append(r_guessing_single_accuracy, single_accuracy)\n",
    "    r_guessing_class_accuracy = np.append(r_guessing_class_accuracy, class_accuracy)\n",
    "    r_guessing_total_accuracy = np.append(r_guessing_total_accuracy, total_accuracy)\n",
    "    \n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果整理\n",
    "res_dataFrame = pd.DataFrame({\"normal_single_accuracy\":normal_single_accuracy,\n",
    "                              \"speeding_single_accuracy\":speeding_single_accuracy,\n",
    "                              \"cheating_single_accuracy\":cheating_single_accuracy,\n",
    "                              \"r_guessing_single_accuracy\":r_guessing_single_accuracy,\n",
    "                              \"normal_class_accuracy\":normal_class_accuracy,\n",
    "                              \"speeding_class_accuracy\":speeding_class_accuracy,\n",
    "                              \"cheating_class_accuracy\":cheating_class_accuracy,\n",
    "                              \"r_guessing_class_accuracy\":r_guessing_class_accuracy,\n",
    "                              \"normal_total_accuracy\":normal_total_accuracy,\n",
    "                              \"speeding_total_accuracy\":speeding_total_accuracy,\n",
    "                              \"cheating_total_accuracy\":cheating_total_accuracy,\n",
    "                              \"r_guessing_total_accuracy\":r_guessing_total_accuracy})\n",
    "res_dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef4eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce797c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
