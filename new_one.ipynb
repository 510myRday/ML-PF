{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d203ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "531427fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义函数 -----------------------------------------------------------------------------------------------------\n",
    "def name_to_str(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def find_index(index, pred_type):\n",
    "    equal = np.empty(0)\n",
    "    for i in np.arange(0, pred_type.size):\n",
    "        count = index.count(pred_type[i])\n",
    "        if count == 0:\n",
    "            equal = np.append(equal, \"False\")\n",
    "        else:\n",
    "            equal = np.append(equal, \"True\")\n",
    "    return pd.DataFrame({\"equal\":equal})\n",
    "\n",
    "def result(test_x, test_y):\n",
    "    # 预测\n",
    "    pred = model.predict(test_x)\n",
    "    truth_type = test_y.argmax(axis = 1)\n",
    "    pred_type = pred.argmax(axis = 1)\n",
    "    \n",
    "    # test准确性\n",
    "    single_accuracy = round(model.evaluate(test_x, test_y)[1], 3)\n",
    "    print(\"\\n★--- Single_accuracy:\", single_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    # 获取对应索引\n",
    "    name = name_to_str(pred_x,globals())[0]\n",
    "    if name == \"x_test_normal\": class_index = normal_index; total_index = normal_index\n",
    "    if name == \"x_test_speeding\": class_index = speeding_index; total_index = aberrant_index\n",
    "    if name == \"x_test_cheating\": class_index = cheating_index; total_index = aberrant_index\n",
    "    if name == \"x_test_r_guessing\": class_index = r_guessing_index; total_index = aberrant_index\n",
    "    # print(class_index, total_index)\n",
    "    \n",
    "    # class准确性\n",
    "    class_df = find_index(class_index, pred_type)\n",
    "    class_accuracy = round(class_df.value_counts()[\"True\"] / class_df.size, 3)\n",
    "    \n",
    "    print(\"\\n★--- Class_accuracy:\", class_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    # total准确性\n",
    "    total_df = find_index(total_index, pred_type)\n",
    "    total_accuracy = round(total_df.value_counts()[\"True\"] / total_df.size, 3)\n",
    "    print(\"\\n★--- Total_accuracy:\", total_accuracy)\n",
    "    print(\"\\n------------------------------------------------------------------\")\n",
    "    \n",
    "    return single_accuracy, class_accuracy, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413f5cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/14 22:59:05\n",
      "--------------------- running 1 ---------------------\n",
      "x_train.shape: (92500, 20)\n",
      "y_train.shape: (92500, 256)\n",
      "Epoch 1/100\n",
      "1006/1006 [==============================] - 3s 2ms/step - loss: 5.3643 - accuracy: 0.0143 - val_loss: 5.0947 - val_accuracy: 0.0296\n",
      "Epoch 2/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 4.7955 - accuracy: 0.0606 - val_loss: 4.5236 - val_accuracy: 0.1098\n",
      "Epoch 3/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 4.2746 - accuracy: 0.1638 - val_loss: 4.0481 - val_accuracy: 0.2300\n",
      "Epoch 4/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 3.8273 - accuracy: 0.2774 - val_loss: 3.6293 - val_accuracy: 0.3247\n",
      "Epoch 5/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 3.4334 - accuracy: 0.3600 - val_loss: 3.2622 - val_accuracy: 0.3882\n",
      "Epoch 6/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 3.0927 - accuracy: 0.4184 - val_loss: 2.9485 - val_accuracy: 0.4414\n",
      "Epoch 7/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 2.8044 - accuracy: 0.4643 - val_loss: 2.6860 - val_accuracy: 0.4789\n",
      "Epoch 8/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 2.5645 - accuracy: 0.4946 - val_loss: 2.4691 - val_accuracy: 0.5106\n",
      "Epoch 9/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 2.3674 - accuracy: 0.5219 - val_loss: 2.2907 - val_accuracy: 0.5281\n",
      "Epoch 10/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 2.2054 - accuracy: 0.5375 - val_loss: 2.1448 - val_accuracy: 0.5450\n",
      "Epoch 11/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 2.0728 - accuracy: 0.5496 - val_loss: 2.0248 - val_accuracy: 0.5530\n",
      "Epoch 12/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.9638 - accuracy: 0.5569 - val_loss: 1.9261 - val_accuracy: 0.5611\n",
      "Epoch 13/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.8741 - accuracy: 0.5642 - val_loss: 1.8455 - val_accuracy: 0.5656\n",
      "Epoch 14/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.8003 - accuracy: 0.5686 - val_loss: 1.7785 - val_accuracy: 0.5712\n",
      "Epoch 15/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.7393 - accuracy: 0.5725 - val_loss: 1.7230 - val_accuracy: 0.5739\n",
      "Epoch 16/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.6888 - accuracy: 0.5757 - val_loss: 1.6775 - val_accuracy: 0.5762\n",
      "Epoch 17/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.6466 - accuracy: 0.5784 - val_loss: 1.6391 - val_accuracy: 0.5807\n",
      "Epoch 18/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.6113 - accuracy: 0.5810 - val_loss: 1.6069 - val_accuracy: 0.5812\n",
      "Epoch 19/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.5815 - accuracy: 0.5826 - val_loss: 1.5793 - val_accuracy: 0.5842\n",
      "Epoch 20/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.5562 - accuracy: 0.5847 - val_loss: 1.5567 - val_accuracy: 0.5864\n",
      "Epoch 21/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.5345 - accuracy: 0.5861 - val_loss: 1.5364 - val_accuracy: 0.5853\n",
      "Epoch 22/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.5161 - accuracy: 0.5860 - val_loss: 1.5188 - val_accuracy: 0.5875\n",
      "Epoch 23/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4997 - accuracy: 0.5881 - val_loss: 1.5043 - val_accuracy: 0.5884\n",
      "Epoch 24/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4857 - accuracy: 0.5892 - val_loss: 1.4909 - val_accuracy: 0.5897\n",
      "Epoch 25/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4732 - accuracy: 0.5902 - val_loss: 1.4797 - val_accuracy: 0.5905\n",
      "Epoch 26/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4625 - accuracy: 0.5917 - val_loss: 1.4688 - val_accuracy: 0.5917\n",
      "Epoch 27/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4525 - accuracy: 0.5925 - val_loss: 1.4600 - val_accuracy: 0.5916\n",
      "Epoch 28/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4439 - accuracy: 0.5929 - val_loss: 1.4519 - val_accuracy: 0.5942\n",
      "Epoch 29/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4359 - accuracy: 0.5942 - val_loss: 1.4447 - val_accuracy: 0.5949\n",
      "Epoch 30/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4286 - accuracy: 0.5947 - val_loss: 1.4379 - val_accuracy: 0.5953\n",
      "Epoch 31/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4220 - accuracy: 0.5961 - val_loss: 1.4323 - val_accuracy: 0.5951\n",
      "Epoch 32/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4160 - accuracy: 0.5963 - val_loss: 1.4262 - val_accuracy: 0.5975\n",
      "Epoch 33/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4104 - accuracy: 0.5974 - val_loss: 1.4214 - val_accuracy: 0.5981\n",
      "Epoch 34/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4052 - accuracy: 0.5982 - val_loss: 1.4166 - val_accuracy: 0.5981\n",
      "Epoch 35/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.4002 - accuracy: 0.5988 - val_loss: 1.4122 - val_accuracy: 0.5986\n",
      "Epoch 36/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3957 - accuracy: 0.5991 - val_loss: 1.4077 - val_accuracy: 0.5997\n",
      "Epoch 37/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3916 - accuracy: 0.6003 - val_loss: 1.4040 - val_accuracy: 0.5999\n",
      "Epoch 38/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3876 - accuracy: 0.6000 - val_loss: 1.4004 - val_accuracy: 0.6010\n",
      "Epoch 39/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3839 - accuracy: 0.6011 - val_loss: 1.3972 - val_accuracy: 0.6016\n",
      "Epoch 40/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3804 - accuracy: 0.6012 - val_loss: 1.3940 - val_accuracy: 0.6002\n",
      "Epoch 41/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3770 - accuracy: 0.6016 - val_loss: 1.3907 - val_accuracy: 0.6019\n",
      "Epoch 42/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3738 - accuracy: 0.6022 - val_loss: 1.3881 - val_accuracy: 0.6024\n",
      "Epoch 43/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3707 - accuracy: 0.6022 - val_loss: 1.3847 - val_accuracy: 0.6025\n",
      "Epoch 44/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3678 - accuracy: 0.6030 - val_loss: 1.3824 - val_accuracy: 0.6031\n",
      "Epoch 45/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3651 - accuracy: 0.6034 - val_loss: 1.3806 - val_accuracy: 0.6036\n",
      "Epoch 46/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3624 - accuracy: 0.6040 - val_loss: 1.3776 - val_accuracy: 0.6042\n",
      "Epoch 47/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3599 - accuracy: 0.6045 - val_loss: 1.3754 - val_accuracy: 0.6035\n",
      "Epoch 48/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3573 - accuracy: 0.6049 - val_loss: 1.3731 - val_accuracy: 0.6049\n",
      "Epoch 49/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3553 - accuracy: 0.6052 - val_loss: 1.3714 - val_accuracy: 0.6057\n",
      "Epoch 50/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3528 - accuracy: 0.6059 - val_loss: 1.3693 - val_accuracy: 0.6046\n",
      "Epoch 51/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3507 - accuracy: 0.6061 - val_loss: 1.3672 - val_accuracy: 0.6058\n",
      "Epoch 52/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3485 - accuracy: 0.6061 - val_loss: 1.3651 - val_accuracy: 0.6056\n",
      "Epoch 53/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3465 - accuracy: 0.6064 - val_loss: 1.3630 - val_accuracy: 0.6064\n",
      "Epoch 54/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3444 - accuracy: 0.6066 - val_loss: 1.3625 - val_accuracy: 0.6055\n",
      "Epoch 55/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3426 - accuracy: 0.6067 - val_loss: 1.3604 - val_accuracy: 0.6071\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3407 - accuracy: 0.6071 - val_loss: 1.3593 - val_accuracy: 0.6069\n",
      "Epoch 57/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3390 - accuracy: 0.6073 - val_loss: 1.3568 - val_accuracy: 0.6073\n",
      "Epoch 58/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3372 - accuracy: 0.6084 - val_loss: 1.3552 - val_accuracy: 0.6076\n",
      "Epoch 59/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3355 - accuracy: 0.6082 - val_loss: 1.3539 - val_accuracy: 0.6084\n",
      "Epoch 60/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3339 - accuracy: 0.6078 - val_loss: 1.3531 - val_accuracy: 0.6089\n",
      "Epoch 61/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3325 - accuracy: 0.6088 - val_loss: 1.3512 - val_accuracy: 0.6085\n",
      "Epoch 62/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3307 - accuracy: 0.6088 - val_loss: 1.3492 - val_accuracy: 0.6089\n",
      "Epoch 63/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3291 - accuracy: 0.6089 - val_loss: 1.3491 - val_accuracy: 0.6091\n",
      "Epoch 64/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3278 - accuracy: 0.6091 - val_loss: 1.3471 - val_accuracy: 0.6092\n",
      "Epoch 65/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3262 - accuracy: 0.6092 - val_loss: 1.3463 - val_accuracy: 0.6097\n",
      "Epoch 66/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3250 - accuracy: 0.6094 - val_loss: 1.3452 - val_accuracy: 0.6098\n",
      "Epoch 67/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3236 - accuracy: 0.6090 - val_loss: 1.3437 - val_accuracy: 0.6092\n",
      "Epoch 68/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3222 - accuracy: 0.6097 - val_loss: 1.3426 - val_accuracy: 0.6097\n",
      "Epoch 69/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3210 - accuracy: 0.6093 - val_loss: 1.3410 - val_accuracy: 0.6094\n",
      "Epoch 70/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3196 - accuracy: 0.6099 - val_loss: 1.3405 - val_accuracy: 0.6101\n",
      "Epoch 71/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3183 - accuracy: 0.6100 - val_loss: 1.3398 - val_accuracy: 0.6101\n",
      "Epoch 72/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3172 - accuracy: 0.6102 - val_loss: 1.3384 - val_accuracy: 0.6109\n",
      "Epoch 73/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3160 - accuracy: 0.6108 - val_loss: 1.3378 - val_accuracy: 0.6102\n",
      "Epoch 74/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3148 - accuracy: 0.6108 - val_loss: 1.3365 - val_accuracy: 0.6105\n",
      "Epoch 75/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3136 - accuracy: 0.6105 - val_loss: 1.3362 - val_accuracy: 0.6102\n",
      "Epoch 76/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3126 - accuracy: 0.6116 - val_loss: 1.3343 - val_accuracy: 0.6106\n",
      "Epoch 77/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3112 - accuracy: 0.6110 - val_loss: 1.3338 - val_accuracy: 0.6108\n",
      "Epoch 78/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3103 - accuracy: 0.6110 - val_loss: 1.3332 - val_accuracy: 0.6105\n",
      "Epoch 79/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3095 - accuracy: 0.6110 - val_loss: 1.3319 - val_accuracy: 0.6112\n",
      "Epoch 80/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3084 - accuracy: 0.6115 - val_loss: 1.3308 - val_accuracy: 0.6116\n",
      "Epoch 81/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3072 - accuracy: 0.6116 - val_loss: 1.3299 - val_accuracy: 0.6115\n",
      "Epoch 82/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3063 - accuracy: 0.6117 - val_loss: 1.3292 - val_accuracy: 0.6110\n",
      "Epoch 83/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3053 - accuracy: 0.6118 - val_loss: 1.3288 - val_accuracy: 0.6119\n",
      "Epoch 84/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3044 - accuracy: 0.6119 - val_loss: 1.3279 - val_accuracy: 0.6114\n",
      "Epoch 85/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3033 - accuracy: 0.6124 - val_loss: 1.3278 - val_accuracy: 0.6113\n",
      "Epoch 86/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3025 - accuracy: 0.6126 - val_loss: 1.3270 - val_accuracy: 0.6116\n",
      "Epoch 87/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3015 - accuracy: 0.6122 - val_loss: 1.3260 - val_accuracy: 0.6122\n",
      "Epoch 88/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.3007 - accuracy: 0.6125 - val_loss: 1.3247 - val_accuracy: 0.6119\n",
      "Epoch 89/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2998 - accuracy: 0.6125 - val_loss: 1.3245 - val_accuracy: 0.6121\n",
      "Epoch 90/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2989 - accuracy: 0.6127 - val_loss: 1.3235 - val_accuracy: 0.6121\n",
      "Epoch 91/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2981 - accuracy: 0.6131 - val_loss: 1.3230 - val_accuracy: 0.6117\n",
      "Epoch 92/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2973 - accuracy: 0.6127 - val_loss: 1.3222 - val_accuracy: 0.6123\n",
      "Epoch 93/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2965 - accuracy: 0.6128 - val_loss: 1.3215 - val_accuracy: 0.6123\n",
      "Epoch 94/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2958 - accuracy: 0.6130 - val_loss: 1.3205 - val_accuracy: 0.6122\n",
      "Epoch 95/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2948 - accuracy: 0.6137 - val_loss: 1.3208 - val_accuracy: 0.6123\n",
      "Epoch 96/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2942 - accuracy: 0.6128 - val_loss: 1.3197 - val_accuracy: 0.6130\n",
      "Epoch 97/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2933 - accuracy: 0.6131 - val_loss: 1.3192 - val_accuracy: 0.6125\n",
      "Epoch 98/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2926 - accuracy: 0.6132 - val_loss: 1.3182 - val_accuracy: 0.6128\n",
      "Epoch 99/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2917 - accuracy: 0.6136 - val_loss: 1.3182 - val_accuracy: 0.6129\n",
      "Epoch 100/100\n",
      "1006/1006 [==============================] - 2s 2ms/step - loss: 1.2910 - accuracy: 0.6134 - val_loss: 1.3177 - val_accuracy: 0.6128\n",
      "['x_test_normal', 'pred_x']\n",
      "1000/1000 [==============================] - 1s 743us/step\n",
      "1000/1000 [==============================] - 1s 988us/step - loss: 1.3276 - accuracy: 0.6357\n",
      "\n",
      "★--- Single_accuracy: 0.636\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.851\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.851\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_speeding', 'pred_x']\n",
      "891/891 [==============================] - 1s 741us/step\n",
      "891/891 [==============================] - 1s 873us/step - loss: 1.4689 - accuracy: 0.4860\n",
      "\n",
      "★--- Single_accuracy: 0.486\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.63\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.681\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_cheating', 'pred_x']\n",
      "985/985 [==============================] - 1s 730us/step\n",
      "985/985 [==============================] - 1s 941us/step - loss: 1.0586 - accuracy: 0.7065\n",
      "\n",
      "★--- Single_accuracy: 0.707\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.977\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.997\n",
      "\n",
      "------------------------------------------------------------------\n",
      "['x_test_r_guessing', 'pred_x']\n",
      "16/16 [==============================] - 0s 810us/step\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 8.2589 - accuracy: 0.0000e+00\n",
      "\n",
      "★--- Single_accuracy: 0.0\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Class_accuracy: 0.01\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "★--- Total_accuracy: 0.624\n",
      "\n",
      "------------------------------------------------------------------\n",
      "2022/11/14 23:04:39\n"
     ]
    }
   ],
   "source": [
    "# 生成保存结果的数组 -----------------\n",
    "normal_single_accuracy = np.empty(0)\n",
    "speeding_single_accuracy = np.empty(0)\n",
    "cheating_single_accuracy = np.empty(0)\n",
    "r_guessing_single_accuracy = np.empty(0)\n",
    "\n",
    "normal_class_accuracy = np.empty(0)\n",
    "speeding_class_accuracy = np.empty(0)\n",
    "cheating_class_accuracy = np.empty(0)\n",
    "r_guessing_class_accuracy = np.empty(0)\n",
    "\n",
    "normal_total_accuracy = np.empty(0)\n",
    "speeding_total_accuracy = np.empty(0)\n",
    "cheating_total_accuracy = np.empty(0)\n",
    "r_guessing_total_accuracy = np.empty(0)\n",
    "\n",
    "# 重复50次 (1:51) -----------------------------\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()))\n",
    "for rs in np.arange(1, 2):\n",
    "    \n",
    "    ########## 数据参数 ##########\n",
    "    start_name = \"Q_6_20_high_0.2\"\n",
    "    seed = str(rs)\n",
    "    hasRT = \"F\"\n",
    "    ##############################\n",
    "    print(\"--------------------- running \" + seed + \" ---------------------\")\n",
    "    \n",
    "    # 读入数据 ---------------------\n",
    "    train_x_path = \"./DATA2/\" + seed + \"s_\" + start_name + \"_train_x_\" + hasRT + \".csv\"\n",
    "    train_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_train_y.csv\"\n",
    "\n",
    "    test_normal_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_normal_x_\" + hasRT + \".csv\"\n",
    "    test_normal_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_normal_y.csv\"\n",
    "    test_cheating_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_cheating_x_\" + hasRT + \".csv\"\n",
    "    test_cheating_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_cheating_y.csv\"\n",
    "    test_speeding_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_speeding_x_\" + hasRT + \".csv\"\n",
    "    test_speeding_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_speeding_y.csv\"\n",
    "    test_r_guessing_x_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_r_guessing_x_\" + hasRT + \".csv\"\n",
    "    test_r_guessing_y_path = \"./DATA2/\"  + seed + \"s_\" + start_name + \"_test_r_guessing_y.csv\"\n",
    "\n",
    "    x_train = np.array(pd.read_csv(train_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_train = np.array(pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "\n",
    "    x_test_normal = np.array(pd.read_csv(test_normal_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_normal = np.array(pd.read_csv(test_normal_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_cheating = np.array(pd.read_csv(test_cheating_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_cheating = np.array(pd.read_csv(test_cheating_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_speeding = np.array(pd.read_csv(test_speeding_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_speeding = np.array(pd.read_csv(test_speeding_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    x_test_r_guessing = np.array(pd.read_csv(test_r_guessing_x_path).drop(\"Unnamed: 0\", axis=1))\n",
    "    y_test_r_guessing = np.array(pd.read_csv(test_r_guessing_y_path).drop(\"Unnamed: 0\", axis=1))\n",
    "\n",
    "    # 获取异常类索引 ---------------\n",
    "    def get_same_element_index(ob_list, word):\n",
    "        return [i for (i, v) in enumerate(ob_list) if v == word]\n",
    "\n",
    "    normal_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('normal').tolist()\n",
    "    speeding_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('speeding').tolist()\n",
    "    cheating_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('cheating').tolist()\n",
    "    r_guessing_list = pd.read_csv(train_y_path).drop(\"Unnamed: 0\", axis=1).columns.str.contains('r_guessing').tolist()\n",
    "\n",
    "    normal_index = get_same_element_index(normal_list, True)\n",
    "    aberrant_index = get_same_element_index(normal_list, False)\n",
    "    speeding_index = get_same_element_index(speeding_list, True)\n",
    "    cheating_index = get_same_element_index(cheating_list, True)\n",
    "    r_guessing_index = get_same_element_index(r_guessing_list, True)\n",
    "    \n",
    "\n",
    "    # 训练集——测试集划分（5-5） ---\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,train_size=0.5,random_state=666)\n",
    "    print(\"x_train.shape:\", x_train.shape)\n",
    "    print(\"y_train.shape:\", y_train.shape)\n",
    "    \n",
    "    ########## 模型参数 ##########\n",
    "    layer_one = x_train.shape[1] - 1\n",
    "    batch_size = int(x_train.shape[0] / 1000)\n",
    "    learning_rate=0.0001\n",
    "    epochs = 100\n",
    "    ##############################\n",
    "    \n",
    "    # 构建模型 -----------------------\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = layer_one, input_dim = x_train.shape[1], activation = \"relu\"))\n",
    "    model.add(Dense(units = y_train.shape[1], activation = \"softmax\"))\n",
    "    \n",
    "    adam = Adam(learning_rate = learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    \n",
    "    # 训练模型 ------------------------\n",
    "    H = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), workers=20, use_multiprocessing=True)\n",
    "    \n",
    "    # normal结果 ----------------------\n",
    "    pred_x = x_test_normal\n",
    "    pred_y = y_test_normal\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    normal_single_accuracy = np.append(normal_single_accuracy, single_accuracy)\n",
    "    normal_class_accuracy = np.append(normal_class_accuracy, class_accuracy)\n",
    "    normal_total_accuracy = np.append(normal_total_accuracy, total_accuracy)\n",
    "    \n",
    "    # speeding结果 --------------------\n",
    "    pred_x = x_test_speeding\n",
    "    pred_y = y_test_speeding\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    speeding_single_accuracy = np.append(speeding_single_accuracy, single_accuracy)\n",
    "    speeding_class_accuracy = np.append(speeding_class_accuracy, class_accuracy)\n",
    "    speeding_total_accuracy = np.append(speeding_total_accuracy, total_accuracy)\n",
    "\n",
    "    # cheating结果 ---------------------\n",
    "    pred_x = x_test_cheating\n",
    "    pred_y = y_test_cheating\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    cheating_single_accuracy = np.append(cheating_single_accuracy, single_accuracy)\n",
    "    cheating_class_accuracy = np.append(cheating_class_accuracy, class_accuracy)\n",
    "    cheating_total_accuracy = np.append(cheating_total_accuracy, total_accuracy)\n",
    "\n",
    "    # r_guessing结果 -------------------\n",
    "    pred_x = x_test_r_guessing\n",
    "    pred_y = y_test_r_guessing\n",
    "    print(name_to_str(pred_x,globals()))\n",
    "    single_accuracy, class_accuracy, total_accuracy = result(pred_x, pred_y)\n",
    "    r_guessing_single_accuracy = np.append(r_guessing_single_accuracy, single_accuracy)\n",
    "    r_guessing_class_accuracy = np.append(r_guessing_class_accuracy, class_accuracy)\n",
    "    r_guessing_total_accuracy = np.append(r_guessing_total_accuracy, total_accuracy)\n",
    "    \n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c74823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_single_accuracy</th>\n",
       "      <th>speeding_single_accuracy</th>\n",
       "      <th>cheating_single_accuracy</th>\n",
       "      <th>r_guessing_single_accuracy</th>\n",
       "      <th>normal_class_accuracy</th>\n",
       "      <th>speeding_class_accuracy</th>\n",
       "      <th>cheating_class_accuracy</th>\n",
       "      <th>r_guessing_class_accuracy</th>\n",
       "      <th>normal_total_accuracy</th>\n",
       "      <th>speeding_total_accuracy</th>\n",
       "      <th>cheating_total_accuracy</th>\n",
       "      <th>r_guessing_total_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normal_single_accuracy  speeding_single_accuracy  cheating_single_accuracy  \\\n",
       "0                   0.636                     0.486                     0.707   \n",
       "\n",
       "   r_guessing_single_accuracy  normal_class_accuracy  speeding_class_accuracy  \\\n",
       "0                         0.0                  0.851                     0.63   \n",
       "\n",
       "   cheating_class_accuracy  r_guessing_class_accuracy  normal_total_accuracy  \\\n",
       "0                    0.977                       0.01                  0.851   \n",
       "\n",
       "   speeding_total_accuracy  cheating_total_accuracy  r_guessing_total_accuracy  \n",
       "0                    0.681                    0.997                      0.624  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果整理\n",
    "res_dataFrame = pd.DataFrame({\"normal_single_accuracy\":normal_single_accuracy,\n",
    "                              \"speeding_single_accuracy\":speeding_single_accuracy,\n",
    "                              \"cheating_single_accuracy\":cheating_single_accuracy,\n",
    "                              \"r_guessing_single_accuracy\":r_guessing_single_accuracy,\n",
    "                              \"normal_class_accuracy\":normal_class_accuracy,\n",
    "                              \"speeding_class_accuracy\":speeding_class_accuracy,\n",
    "                              \"cheating_class_accuracy\":cheating_class_accuracy,\n",
    "                              \"r_guessing_class_accuracy\":r_guessing_class_accuracy,\n",
    "                              \"normal_total_accuracy\":normal_total_accuracy,\n",
    "                              \"speeding_total_accuracy\":speeding_total_accuracy,\n",
    "                              \"cheating_total_accuracy\":cheating_total_accuracy,\n",
    "                              \"r_guessing_total_accuracy\":r_guessing_total_accuracy})\n",
    "res_dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49ef4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出\n",
    "res_dataFrame.to_csv(path_or_buf = \"./res2/\" + start_name + \"_\" + hasRT + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce797c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
